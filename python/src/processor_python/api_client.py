"""
API client for Google Maps review extraction using SerpApi.

Provides deterministic, rate-limited access to review data with proper error handling
and NDJSON output format.
"""

import json
import os
import time
from datetime import datetime
from typing import Any, Dict, Iterator, Optional

from .schema import ReviewV1

try:
    from serpapi import GoogleSearch
    SERPAPI_AVAILABLE = True
except ImportError:
    SERPAPI_AVAILABLE = False
    GoogleSearch = None

class SerpApiClient:
    """
    Client for extracting Google Maps reviews using SerpApi.
    
    Features:
    - Rate limiting to respect API quotas
    - Pagination handling for complete data extraction
    - Schema validation and normalization
    - Error recovery and retry logic
    """
    
    def __init__(self, api_key: Optional[str] = None, rate_limit_delay: float = 1.0):
        if not SERPAPI_AVAILABLE:
            raise ImportError("serpapi package not installed. Run: pip install serpapi")
        
        self.api_key = api_key or os.getenv('SERPAPI_KEY')
        if not self.api_key:
            raise ValueError("SerpApi key required. Set SERPAPI_KEY environment variable or pass api_key parameter")
        
        self.rate_limit_delay = rate_limit_delay
        self.last_request_time = 0.0
    
    def _rate_limit(self):
        """Enforce rate limiting between API calls."""
        elapsed = time.time() - self.last_request_time
        if elapsed < self.rate_limit_delay:
            time.sleep(self.rate_limit_delay - elapsed)
        self.last_request_time = time.time()
    
    def _make_request(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Make a rate-limited request to SerpApi."""
        self._rate_limit()
        
        search = GoogleSearch(params)
        result = search.get_dict()
        
        if 'error' in result:
            raise Exception(f"SerpApi error: {result['error']}")
        
        return result
    
    def extract_reviews(self, place_id: str, max_pages: Optional[int] = None) -> Iterator[Dict[str, Any]]:
        """
        Extract all reviews for a given place_id.
        
        Args:
            place_id: Google Maps place ID
            max_pages: Maximum number of pages to fetch (None for all)
            
        Yields:
            Normalized review records
        """
        params = {
            'engine': 'google_maps_reviews',
            'place_id': place_id,
            'api_key': self.api_key,
        }
        
        page_count = 0
        
        while True:
            if max_pages and page_count >= max_pages:
                break
            
            try:
                result = self._make_request(params)
                reviews = result.get('reviews', [])
                
                if not reviews:
                    break
                
                for review in reviews:
                    yield self._normalize_review(review, place_id)
                
                page_count += 1
                
                # Check for next page
                next_page_token = result.get('serpapi_pagination', {}).get('next_page_token')
                if not next_page_token:
                    break
                
                params['next_page_token'] = next_page_token
                
            except Exception as e:
                print(f"Warning: Error fetching page {page_count + 1} for {place_id}: {e}")
                break
    
    def _normalize_review(self, raw_review: Dict[str, Any], place_id: str) -> Dict[str, Any]:
        """Normalize raw SerpApi review data to our schema format."""
        user_info = raw_review.get('user', {})
        
        # Generate review ID from available data
        review_id = (
            raw_review.get('review_id') or
            f"{place_id}_{user_info.get('name', 'unknown')}_{raw_review.get('date', '')}"
        ).replace(' ', '_').replace('/', '_')
        
        # Parse timestamp
        timestamp = None
        if raw_review.get('date'):
            try:
                # SerpApi typically returns relative dates like "2 weeks ago"
                # For now, use current timestamp - this could be enhanced with better parsing
                timestamp = datetime.now().isoformat()
            except Exception:
                pass
        
        return {
            'schema_version': '1.0',
            'place_id': place_id,
            'review_id': review_id,
            'user': user_info.get('name'),
            'rating': raw_review.get('rating'),
            'text': raw_review.get('snippet') or raw_review.get('text'),
            'ts': timestamp,
            'likes': raw_review.get('likes'),
            'lang': raw_review.get('language')
        }
    
    def extract_to_ndjson(self, place_id: str, output_file: str, max_pages: Optional[int] = None):
        """
        Extract reviews and save to NDJSON file.
        
        Args:
            place_id: Google Maps place ID
            output_file: Path to output NDJSON file
            max_pages: Maximum number of pages to fetch
        """
        count = 0
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for review in self.extract_reviews(place_id, max_pages):
                # Validate against schema
                try:
                    validated = ReviewV1(**review)
                    f.write(json.dumps(validated.model_dump(), ensure_ascii=False) + '\n')
                    count += 1
                except Exception as e:
                    print(f"Warning: Skipping invalid review: {e}")
        
        print(f"Extracted {count} reviews for {place_id} â†’ {output_file}")

def extract_place_reviews(place_id: str, output_file: str, api_key: Optional[str] = None, max_pages: Optional[int] = None):
    """
    Convenience function to extract reviews for a single place.
    
    Args:
        place_id: Google Maps place ID
        output_file: Path to output NDJSON file
        api_key: SerpApi key (or set SERPAPI_KEY env var)
        max_pages: Maximum pages to fetch
    """
    client = SerpApiClient(api_key)
    client.extract_to_ndjson(place_id, output_file, max_pages)

# Example usage
if __name__ == '__main__':
    import sys
    
    if len(sys.argv) < 3:
        print("Usage: python api_client.py <place_id> <output_file> [max_pages]")
        sys.exit(1)
    
    place_id = sys.argv[1]
    output_file = sys.argv[2]
    max_pages = int(sys.argv[3]) if len(sys.argv) > 3 else None
    
    extract_place_reviews(place_id, output_file, max_pages=max_pages)
